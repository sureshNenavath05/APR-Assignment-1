{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe186125",
   "metadata": {},
   "source": [
    "# APR Assignment: Anime Score Classification\n",
    "\n",
    "**Name:** Nenavath Suresh  \n",
    "**Roll No:** 2201AI25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce99e0f9",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Classify anime shows into score categories (`Very Good`, `Good`, `Average`, `Low`) based on features such as episodes, duration, genres, producers, studios, licensors, source material, and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f06267d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 1.7.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import sklearn\n",
    "\n",
    "print(\"scikit-learn version:\", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd032821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset shape: (17562, 35)\n",
      "Columns: ['MAL_ID', 'Name', 'Score', 'Genres', 'English name', 'Japanese name', 'Type', 'Episodes', 'Aired', 'Premiered', 'Producers', 'Licensors', 'Studios', 'Source', 'Duration', 'Rating', 'Ranked', 'Popularity', 'Members', 'Favorites', 'Watching', 'Completed', 'On-Hold', 'Dropped', 'Plan to Watch', 'Score-10', 'Score-9', 'Score-8', 'Score-7', 'Score-6', 'Score-5', 'Score-4', 'Score-3', 'Score-2', 'Score-1']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"anime.csv\")\n",
    "print(\"Initial dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4396a231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['Score', 'Score-10', 'Score-9', 'Score-8', 'Score-7', 'Score-6', 'Score-5', 'Score-4', 'Score-3', 'Score-2', 'Score-1']\n",
      "Target class distribution:\n",
      " Score_Class\n",
      "Average      5300\n",
      "Low          3341\n",
      "Good         3232\n",
      "Very Good     548\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['Score'] = pd.to_numeric(df['Score'], errors='coerce')\n",
    "df = df.dropna(subset=['Score']).reset_index(drop=True)\n",
    "\n",
    "def bucket_score(s):\n",
    "    if s >= 8.0: return \"Very Good\"\n",
    "    elif s >= 7.0: return \"Good\"\n",
    "    elif s >= 6.0: return \"Average\"\n",
    "    else: return \"Low\"\n",
    "\n",
    "df['Score_Class'] = df['Score'].apply(bucket_score)\n",
    "\n",
    "score_cols = [c for c in df.columns if c.lower().startswith('score-') or c == 'Score']\n",
    "df_features = df.drop(columns=score_cols)\n",
    "\n",
    "print(\"Dropped columns:\", score_cols)\n",
    "print(\"Target class distribution:\\n\", df['Score_Class'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e676226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature preprocessing done.\n",
      "Sample data:\n",
      "    MAL_ID                             Name  \\\n",
      "0       1                     Cowboy Bebop   \n",
      "1       5  Cowboy Bebop: Tengoku no Tobira   \n",
      "\n",
      "                                              Genres            English name  \\\n",
      "0  [Action, Adventure, Comedy, Drama, Sci-Fi, Space]            Cowboy Bebop   \n",
      "1            [Action, Drama, Mystery, Sci-Fi, Space]  Cowboy Bebop:The Movie   \n",
      "\n",
      "    Japanese name   Type  Episodes                        Aired    Premiered  \\\n",
      "0       カウボーイビバップ     TV      26.0  Apr 3, 1998 to Apr 24, 1999  Spring 1998   \n",
      "1  カウボーイビバップ 天国の扉  Movie       1.0                  Sep 1, 2001      Unknown   \n",
      "\n",
      "                  Producers  ... Ranked Popularity  Members  Favorites  \\\n",
      "0           [Bandai Visual]  ...   28.0         39  1251960      61971   \n",
      "1  [Sunrise, Bandai Visual]  ...  159.0        518   273145       1174   \n",
      "\n",
      "  Watching Completed  On-Hold  Dropped  Plan to Watch  Score_Class  \n",
      "0   105808    718161    71513    26678         329800    Very Good  \n",
      "1     4143    208333     1935      770          57964    Very Good  \n",
      "\n",
      "[2 rows x 25 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samasup\\AppData\\Local\\Temp\\ipykernel_6772\\224860240.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_use['Episodes'].fillna(df_use['Episodes'].median(), inplace=True)\n",
      "C:\\Users\\samasup\\AppData\\Local\\Temp\\ipykernel_6772\\224860240.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_use['Duration'].fillna(df_use['Duration'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_use = df_features.copy()\n",
    "\n",
    "df_use['Episodes'] = pd.to_numeric(df_use['Episodes'], errors='coerce')\n",
    "df_use['Episodes'].fillna(df_use['Episodes'].median(), inplace=True)\n",
    "\n",
    "def parse_duration_to_min(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x)\n",
    "    try:\n",
    "        hours = mins = 0\n",
    "        if \"hr\" in s:\n",
    "            parts = s.split()\n",
    "            for i, token in enumerate(parts):\n",
    "                if token.isdigit() and i+1 < len(parts) and parts[i+1].startswith(\"hr\"): hours = int(token)\n",
    "                if token.isdigit() and i+1 < len(parts) and parts[i+1].startswith(\"min\"): mins = int(token)\n",
    "            return hours*60 + mins if (hours or mins) else np.nan\n",
    "        nums = [int(tok) for tok in s.split() if tok.isdigit()]\n",
    "        return nums[0] if nums else np.nan\n",
    "    except: return np.nan\n",
    "\n",
    "df_use['Duration'] = df_use['Duration'].apply(parse_duration_to_min)\n",
    "df_use['Duration'].fillna(df_use['Duration'].median(), inplace=True)\n",
    "\n",
    "def split_to_list(cell):\n",
    "    if pd.isna(cell) or str(cell).strip()==\"\": return []\n",
    "    return [entry.strip() for entry in str(cell).replace(';',',').split(',') if entry.strip()]\n",
    "\n",
    "for col in ['Genres','Producers','Licensors','Studios']:\n",
    "    df_use[col] = df_use[col].apply(split_to_list)\n",
    "\n",
    "df_use['Source'] = df_use['Source'].fillna(\"Unknown\").astype(str)\n",
    "df_use['Rating'] = df_use['Rating'].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "print(\"Feature preprocessing done.\")\n",
    "print(\"Sample data:\\n\", df_use.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4897b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature matrix shape: (12421, 147)\n",
      "Classes in target: ['Very Good' 'Good' 'Average' 'Low']\n"
     ]
    }
   ],
   "source": [
    "min_genre_count = 30\n",
    "mlb_gen = MultiLabelBinarizer()\n",
    "genres_matrix = pd.DataFrame(mlb_gen.fit_transform(df_use['Genres']), columns=mlb_gen.classes_, index=df_use.index)\n",
    "keep_genres = genres_matrix.columns[genres_matrix.sum(axis=0) >= min_genre_count]\n",
    "genres_matrix = genres_matrix[keep_genres]\n",
    "\n",
    "def top_k_multi_label(df_series, k):\n",
    "    all_items = Counter()\n",
    "    for lst in df_series: all_items.update(lst)\n",
    "    return [item for item, _ in all_items.most_common(k)]\n",
    "\n",
    "def make_topk_binary(df_series, topk):\n",
    "    return pd.DataFrame({item: df_series.apply(lambda lst, it=item: int(it in lst)) for item in topk})\n",
    "\n",
    "producers_matrix = make_topk_binary(df_use['Producers'], top_k_multi_label(df_use['Producers'], 40))\n",
    "studios_matrix = make_topk_binary(df_use['Studios'], top_k_multi_label(df_use['Studios'], 40))\n",
    "licensors_matrix = make_topk_binary(df_use['Licensors'], top_k_multi_label(df_use['Licensors'], 20))\n",
    "\n",
    "X = pd.concat([\n",
    "    df_use[['Episodes','Duration','Source','Rating']].reset_index(drop=True),\n",
    "    genres_matrix.reset_index(drop=True),\n",
    "    producers_matrix.reset_index(drop=True),\n",
    "    studios_matrix.reset_index(drop=True),\n",
    "    licensors_matrix.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "y = df['Score_Class'].loc[X.index].copy()\n",
    "print(\"Final feature matrix shape:\", X.shape)\n",
    "print(\"Classes in target:\", y.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a8bc5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 9936 Test size: 2485\n",
      "Preprocessor setup done.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"Train size:\", len(X_train), \"Test size:\", len(X_test))\n",
    "\n",
    "numeric_cols = ['Episodes', 'Duration']\n",
    "categorical_cols = ['Source', 'Rating']\n",
    "\n",
    "enc_params = {\"handle_unknown\": \"ignore\"}\n",
    "if sklearn.__version__ >= \"1.2\":\n",
    "    enc_params[\"sparse_output\"] = False\n",
    "else:\n",
    "    enc_params[\"sparse\"] = False\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_cols),\n",
    "    ('cat', OneHotEncoder(**enc_params), categorical_cols)\n",
    "], remainder='passthrough')\n",
    "\n",
    "print(\"Preprocessor setup done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06d1e7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM training completed.\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC(kernel='rbf', C=10.0, gamma='scale', class_weight='balanced', random_state=42)\n",
    "pipeline = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('clf', svm_clf)\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"SVM training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a0432a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6354124748490946\n",
      "\n",
      "Confusion Matrix:\n",
      "           Average  Good  Low  Very Good\n",
      "Average        667   172  212          9\n",
      "Good           165   408   35         39\n",
      "Low            182    26  460          0\n",
      "Very Good        4    60    2         44\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Average       0.66      0.63      0.64      1060\n",
      "        Good       0.61      0.63      0.62       647\n",
      "         Low       0.65      0.69      0.67       668\n",
      "   Very Good       0.48      0.40      0.44       110\n",
      "\n",
      "    accuracy                           0.64      2485\n",
      "   macro avg       0.60      0.59      0.59      2485\n",
      "weighted avg       0.63      0.64      0.63      2485\n",
      "\n",
      "\n",
      "Test class counts:\n",
      " Score_Class\n",
      "Average      1060\n",
      "Low           668\n",
      "Good          647\n",
      "Very Good     110\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(pd.DataFrame(confusion_matrix(y_test, y_pred, labels=['Average','Good','Low','Very Good']),\n",
    "                   index=['Average','Good','Low','Very Good'],\n",
    "                   columns=['Average','Good','Low','Very Good']))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, labels=['Average','Good','Low','Very Good']))\n",
    "\n",
    "print(\"\\nTest class counts:\\n\", y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6be947c",
   "metadata": {},
   "source": [
    "## Summary & Observations\n",
    "\n",
    "- Accuracy: ~63.5%\n",
    "- Best performance for Average and Low classes.\n",
    "- Very Good class has few samples, leading to lower recall (0.40).\n",
    "- Multi-label features like genres, producers, and studios are important.\n",
    "- Future Work:\n",
    "  - Hyperparameter tuning\n",
    "  - Try ensemble classifiers\n",
    "  - Reduce dimensionality (PCA/feature selection)\n",
    "  - Use embeddings for multi-label features\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
